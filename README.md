# playing with cloud composer
small example that sets up dataproc cluster, runs pyspark (csv2parquet converstion) and deletes cluster

convert.py - simple converstion of a test csv file sitting in GCS

cc-convert4.py - defines a DAG that creates dataproc cluster, runs conversion and deletes cluster



csv file in my case has 9 columns and looks like this

15.0,Sun,0,-73.988204,40.748077,-74.006914,40.707128,1.0,2012-09-16 00:06:07.000000-73.988240.748140.7071-74.0069
3.7,Sun,0,-73.988535,40.723059,-73.990247,40.729007,1.0,2010-01-31 00:47:33.000000-73.988540.723140.729-73.9902
8.0,Sun,2,-73.989582,40.720431,-74.00426,40.722064,4.0,2014-07-20 02:20:38.000000-73.989640.720440.7221-74.0043
10.9,Sun,3,-73.998535,40.72639,-73.987103,40.767985,5.0,2009-05-10 03:37:00.000000-73.998540.726440.768-73.9871
8.5,Sun,6,-73.969838,40.79051,-73.995588,40.759463,1.0,2013-12-08 06:10:15.000000-73.969840.790540.7595-73.9956
14.5,Sun,6,-73.966828,40.804372,-73.997078,40.752503,1.0,2011-03-20 06:05:00.000000-73.966840.804440.7525-73.9971
4.5,Sun,6,-73.991151,40.755695,-74.000709,40.758275,4.0,2011-10-23 06:42:42.000000-73.991240.755740.7583-74.0007
11.7,Sun,6,-73.984042,40.743652,-73.947568,40.796172,1.0,2011-03-20 06:05:00.000000-73.98440.743740.7962-73.9476
